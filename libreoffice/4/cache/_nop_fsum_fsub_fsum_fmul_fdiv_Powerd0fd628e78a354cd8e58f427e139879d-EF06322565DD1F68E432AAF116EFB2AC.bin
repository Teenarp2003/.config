//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32376659
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_75, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power

.entry DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_2,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_3,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_4,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_5,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_6,
	.param .f64 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_7
)
{
	.reg .pred 	%p<136>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<79>;
	.reg .f64 	%fd<348>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd19, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_6];
	mov.b32 	%r16, %envreg3;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %tid.x;
	add.s32 	%r20, %r19, %r16;
	mad.lo.s32 	%r21, %r18, %r17, %r20;
	cvt.s64.s32 	%rd1, %r21;
	setp.gt.s32 	%p1, %r21, 4;
	mov.f64 	%fd325, 0d7FFFFFFFE0000000;
	@%p1 bra 	$L__BB0_2;

	shl.b64 	%rd20, %rd1, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.f64 	%fd325, [%rd21];

$L__BB0_2:
	abs.f64 	%fd75, %fd325;
	setp.le.f64 	%p2, %fd75, 0d7FF0000000000000;
	selp.f64 	%fd3, %fd325, 0d0000000000000000, %p2;
	setp.eq.f64 	%p3, %fd3, 0d3FF0000000000000;
	mov.f64 	%fd329, 0d3FF0000000000000;
	@%p3 bra 	$L__BB0_28;

	abs.f64 	%fd4, %fd3;
	setp.gtu.f64 	%p4, %fd4, 0d7FF0000000000000;
	@%p4 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_4;

$L__BB0_27:
	add.f64 	%fd329, %fd3, 0d3FFCAC083126E979;
	bra.uni 	$L__BB0_28;

$L__BB0_4:
	setp.eq.f64 	%p5, %fd3, 0d7FF0000000000000;
	@%p5 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_5;

$L__BB0_26:
	mov.f64 	%fd263, 0d3FFCAC083126E979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd263;
	}
	setp.gt.s32 	%p28, %r54, -1;
	selp.f64 	%fd329, 0d7FF0000000000000, 0d0000000000000000, %p28;

$L__BB0_28:
	ld.param.u64 	%rd34, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_5];
	cvt.u32.u64 	%r55, %rd1;
	setp.gt.s32 	%p29, %r55, 4;
	add.f64 	%fd23, %fd329, 0d0000000000000000;
	shl.b64 	%rd24, %rd1, 3;
	add.s64 	%rd2, %rd34, %rd24;
	mov.f64 	%fd330, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_30;

	ld.global.f64 	%fd330, [%rd2];

$L__BB0_30:
	abs.f64 	%fd266, %fd330;
	setp.gtu.f64 	%p30, %fd266, 0d7FF0000000000000;
	mov.f64 	%fd339, 0d0000000000000000;
	@%p30 bra 	$L__BB0_56;

	mov.f64 	%fd332, 0d7FFFFFFFE0000000;
	mov.f64 	%fd331, %fd332;
	@%p29 bra 	$L__BB0_33;

	ld.global.f64 	%fd331, [%rd2];

$L__BB0_33:
	ld.param.u64 	%rd35, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_4];
	add.s64 	%rd3, %rd35, %rd24;
	@%p29 bra 	$L__BB0_35;

	ld.global.f64 	%fd332, [%rd3];

$L__BB0_35:
	abs.f64 	%fd270, %fd332;
	setp.gtu.f64 	%p33, %fd270, 0d7FF0000000000000;
	mov.f64 	%fd269, 0d7FF8000000000214;
	mov.f64 	%fd338, %fd269;
	@%p33 bra 	$L__BB0_55;

	mov.f64 	%fd334, 0d7FFFFFFFE0000000;
	mov.f64 	%fd333, %fd334;
	@%p29 bra 	$L__BB0_38;

	ld.global.f64 	%fd333, [%rd3];

$L__BB0_38:
	ld.param.u64 	%rd36, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_3];
	add.s64 	%rd4, %rd36, %rd24;
	@%p29 bra 	$L__BB0_40;

	ld.global.f64 	%fd334, [%rd4];

$L__BB0_40:
	abs.f64 	%fd273, %fd334;
	setp.le.f64 	%p36, %fd273, 0d7FF0000000000000;
	@%p36 bra 	$L__BB0_46;

	mov.f64 	%fd335, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_43;

	ld.global.f64 	%fd335, [%rd3];

$L__BB0_43:
	abs.f64 	%fd275, %fd335;
	setp.gtu.f64 	%p38, %fd275, 0d7FF0000000000000;
	mov.f64 	%fd338, 0d0000000000000000;
	@%p38 bra 	$L__BB0_46;

	@%p29 bra 	$L__BB0_55;

	ld.global.f64 	%fd278, [%rd3];
	setp.neu.f64 	%p40, %fd278, 0d0000000000000000;
	@%p40 bra 	$L__BB0_55;

$L__BB0_46:
	mov.f64 	%fd336, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_48;

	ld.global.f64 	%fd336, [%rd4];

$L__BB0_48:
	abs.f64 	%fd280, %fd336;
	setp.gtu.f64 	%p42, %fd280, 0d7FF0000000000000;
	@%p42 bra 	$L__BB0_53;
	bra.uni 	$L__BB0_49;

$L__BB0_53:
	setp.eq.f64 	%p45, %fd333, 0d0000000000000000;
	mov.f64 	%fd338, %fd269;
	@%p45 bra 	$L__BB0_55;

	rcp.rn.f64 	%fd338, %fd333;
	bra.uni 	$L__BB0_55;

$L__BB0_49:
	setp.eq.f64 	%p43, %fd333, 0d0000000000000000;
	mov.f64 	%fd338, %fd269;
	@%p43 bra 	$L__BB0_55;

	mov.f64 	%fd337, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_52;

	ld.global.f64 	%fd337, [%rd4];

$L__BB0_52:
	div.rn.f64 	%fd338, %fd337, %fd333;

$L__BB0_55:
	mul.f64 	%fd339, %fd331, %fd338;

$L__BB0_56:
	ld.param.u64 	%rd37, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_2];
	add.s64 	%rd5, %rd37, %rd24;
	mov.f64 	%fd340, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_58;

	ld.global.f64 	%fd340, [%rd5];

$L__BB0_58:
	abs.f64 	%fd286, %fd340;
	setp.gtu.f64 	%p47, %fd286, 0d7FF0000000000000;
	mov.f64 	%fd342, 0d0000000000000000;
	@%p47 bra 	$L__BB0_62;

	mov.f64 	%fd341, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_61;

	ld.global.f64 	%fd341, [%rd5];

$L__BB0_61:
	add.f64 	%fd342, %fd341, 0d0000000000000000;

$L__BB0_62:
	ld.param.u64 	%rd38, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_1];
	add.s64 	%rd6, %rd38, %rd24;
	mov.f64 	%fd343, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_64;

	ld.global.f64 	%fd343, [%rd6];

$L__BB0_64:
	abs.f64 	%fd289, %fd343;
	setp.gtu.f64 	%p50, %fd289, 0d7FF0000000000000;
	@%p50 bra 	$L__BB0_82;
	bra.uni 	$L__BB0_65;

$L__BB0_82:
	add.f64 	%fd345, %fd342, 0d0000000000000000;
	bra.uni 	$L__BB0_83;

$L__BB0_65:
	mov.f64 	%fd344, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_67;

	ld.global.f64 	%fd344, [%rd6];

$L__BB0_67:
	setp.gt.f64 	%p52, %fd342, 0d0000000000000000;
	setp.lt.f64 	%p53, %fd344, 0d0000000000000000;
	and.pred  	%p54, %p52, %p53;
	@%p54 bra 	$L__BB0_69;

	setp.geu.f64 	%p55, %fd342, 0d0000000000000000;
	setp.leu.f64 	%p56, %fd344, 0d0000000000000000;
	or.pred  	%p57, %p55, %p56;
	@%p57 bra 	$L__BB0_81;

$L__BB0_69:
	neg.f64 	%fd55, %fd342;
	setp.eq.f64 	%p58, %fd344, %fd55;
	mov.f64 	%fd345, 0d0000000000000000;
	@%p58 bra 	$L__BB0_83;

	setp.eq.f64 	%p59, %fd344, 0d0000000000000000;
	setp.eq.f64 	%p60, %fd342, 0d8000000000000000;
	or.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB0_81;

	add.f64 	%fd292, %fd342, %fd344;
	abs.f64 	%fd56, %fd292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd56;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.eq.s32 	%p62, %r69, 2146435072;
	@%p62 bra 	$L__BB0_81;

	abs.f64 	%fd57, %fd344;
	mul.f64 	%fd293, %fd57, 0d3D30000000000000;
	setp.gt.f64 	%p63, %fd56, %fd293;
	@%p63 bra 	$L__BB0_81;

	abs.f64 	%fd58, %fd55;
	mul.f64 	%fd294, %fd58, 0d3D30000000000000;
	setp.gt.f64 	%p64, %fd56, %fd294;
	@%p64 bra 	$L__BB0_81;

	setp.gtu.f64 	%p65, %fd56, 0d433FFFFFFFFFFFFF;
	@%p65 bra 	$L__BB0_80;

	cvt.rzi.s64.f64 	%rd7, %fd56;
	setp.gt.s64 	%p66, %rd7, 9007199254740991;
	@%p66 bra 	$L__BB0_80;

	cvt.rn.f64.s64 	%fd295, %rd7;
	setp.ne.f64 	%p67, %fd56, %fd295;
	setp.gtu.f64 	%p68, %fd57, 0d433FFFFFFFFFFFFF;
	or.pred  	%p69, %p67, %p68;
	@%p69 bra 	$L__BB0_80;

	cvt.rzi.s64.f64 	%rd8, %fd57;
	setp.gt.s64 	%p70, %rd8, 9007199254740991;
	@%p70 bra 	$L__BB0_80;

	cvt.rn.f64.s64 	%fd296, %rd8;
	setp.ne.f64 	%p71, %fd57, %fd296;
	setp.gtu.f64 	%p72, %fd58, 0d433FFFFFFFFFFFFF;
	or.pred  	%p73, %p71, %p72;
	@%p73 bra 	$L__BB0_80;

	cvt.rzi.s64.f64 	%rd29, %fd58;
	setp.lt.s64 	%p74, %rd29, 9007199254740992;
	cvt.rn.f64.s64 	%fd297, %rd29;
	setp.equ.f64 	%p75, %fd58, %fd297;
	and.pred  	%p76, %p74, %p75;
	@%p76 bra 	$L__BB0_81;

$L__BB0_80:
	mul.f64 	%fd299, %fd57, 0d3CF0000000000000;
	setp.lt.f64 	%p77, %fd56, %fd299;
	mul.f64 	%fd300, %fd58, 0d3CF0000000000000;
	setp.lt.f64 	%p78, %fd56, %fd300;
	and.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB0_83;

$L__BB0_81:
	add.f64 	%fd345, %fd342, %fd344;

$L__BB0_83:
	setp.lt.f64 	%p80, %fd339, 0d0000000000000000;
	setp.lt.f64 	%p81, %fd345, 0d0000000000000000;
	and.pred  	%p82, %p80, %p81;
	@%p82 bra 	$L__BB0_85;

	setp.leu.f64 	%p83, %fd345, 0d0000000000000000;
	setp.leu.f64 	%p84, %fd339, 0d0000000000000000;
	or.pred  	%p85, %p84, %p83;
	@%p85 bra 	$L__BB0_97;

$L__BB0_85:
	setp.eq.f64 	%p86, %fd345, %fd339;
	mov.f64 	%fd346, 0d0000000000000000;
	@%p86 bra 	$L__BB0_98;

	setp.eq.f64 	%p87, %fd345, 0d0000000000000000;
	setp.eq.f64 	%p88, %fd339, 0d0000000000000000;
	or.pred  	%p89, %p88, %p87;
	@%p89 bra 	$L__BB0_97;

	sub.f64 	%fd302, %fd345, %fd339;
	abs.f64 	%fd62, %fd302;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd62;
	}
	and.b32  	%r71, %r70, 2146435072;
	setp.eq.s32 	%p90, %r71, 2146435072;
	@%p90 bra 	$L__BB0_97;

	abs.f64 	%fd63, %fd345;
	mul.f64 	%fd303, %fd63, 0d3D30000000000000;
	setp.gt.f64 	%p91, %fd62, %fd303;
	@%p91 bra 	$L__BB0_97;

	abs.f64 	%fd64, %fd339;
	mul.f64 	%fd304, %fd64, 0d3D30000000000000;
	setp.gt.f64 	%p92, %fd62, %fd304;
	@%p92 bra 	$L__BB0_97;

	setp.gtu.f64 	%p93, %fd62, 0d433FFFFFFFFFFFFF;
	@%p93 bra 	$L__BB0_96;

	cvt.rzi.s64.f64 	%rd9, %fd62;
	setp.gt.s64 	%p94, %rd9, 9007199254740991;
	@%p94 bra 	$L__BB0_96;

	cvt.rn.f64.s64 	%fd305, %rd9;
	setp.ne.f64 	%p95, %fd62, %fd305;
	setp.gtu.f64 	%p96, %fd63, 0d433FFFFFFFFFFFFF;
	or.pred  	%p97, %p95, %p96;
	@%p97 bra 	$L__BB0_96;

	cvt.rzi.s64.f64 	%rd10, %fd63;
	setp.gt.s64 	%p98, %rd10, 9007199254740991;
	@%p98 bra 	$L__BB0_96;

	cvt.rn.f64.s64 	%fd306, %rd10;
	setp.ne.f64 	%p99, %fd63, %fd306;
	setp.gtu.f64 	%p100, %fd64, 0d433FFFFFFFFFFFFF;
	or.pred  	%p101, %p99, %p100;
	@%p101 bra 	$L__BB0_96;

	cvt.rzi.s64.f64 	%rd30, %fd64;
	setp.lt.s64 	%p102, %rd30, 9007199254740992;
	cvt.rn.f64.s64 	%fd307, %rd30;
	setp.equ.f64 	%p103, %fd64, %fd307;
	and.pred  	%p104, %p102, %p103;
	@%p104 bra 	$L__BB0_97;

$L__BB0_96:
	mul.f64 	%fd309, %fd63, 0d3CF0000000000000;
	setp.lt.f64 	%p105, %fd62, %fd309;
	mul.f64 	%fd310, %fd64, 0d3CF0000000000000;
	setp.lt.f64 	%p106, %fd62, %fd310;
	and.pred  	%p107, %p105, %p106;
	@%p107 bra 	$L__BB0_98;

$L__BB0_97:
	sub.f64 	%fd346, %fd345, %fd339;

$L__BB0_98:
	setp.gt.f64 	%p108, %fd23, 0d0000000000000000;
	setp.lt.f64 	%p109, %fd346, 0d0000000000000000;
	and.pred  	%p110, %p108, %p109;
	@%p110 bra 	$L__BB0_100;

	setp.geu.f64 	%p111, %fd23, 0d0000000000000000;
	setp.leu.f64 	%p112, %fd346, 0d0000000000000000;
	or.pred  	%p113, %p111, %p112;
	@%p113 bra 	$L__BB0_112;

$L__BB0_100:
	neg.f64 	%fd67, %fd23;
	setp.eq.f64 	%p114, %fd346, %fd67;
	mov.f64 	%fd347, 0d0000000000000000;
	@%p114 bra 	$L__BB0_113;

	setp.eq.f64 	%p115, %fd346, 0d0000000000000000;
	setp.eq.f64 	%p116, %fd23, 0d8000000000000000;
	or.pred  	%p117, %p116, %p115;
	@%p117 bra 	$L__BB0_112;

	add.f64 	%fd312, %fd23, %fd346;
	abs.f64 	%fd68, %fd312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r72}, %fd68;
	}
	and.b32  	%r73, %r72, 2146435072;
	setp.eq.s32 	%p118, %r73, 2146435072;
	@%p118 bra 	$L__BB0_112;

	abs.f64 	%fd69, %fd346;
	mul.f64 	%fd313, %fd69, 0d3D30000000000000;
	setp.gt.f64 	%p119, %fd68, %fd313;
	@%p119 bra 	$L__BB0_112;

	abs.f64 	%fd70, %fd67;
	mul.f64 	%fd314, %fd70, 0d3D30000000000000;
	setp.gt.f64 	%p120, %fd68, %fd314;
	@%p120 bra 	$L__BB0_112;

	setp.gtu.f64 	%p121, %fd68, 0d433FFFFFFFFFFFFF;
	@%p121 bra 	$L__BB0_111;

	cvt.rzi.s64.f64 	%rd11, %fd68;
	setp.gt.s64 	%p122, %rd11, 9007199254740991;
	@%p122 bra 	$L__BB0_111;

	cvt.rn.f64.s64 	%fd315, %rd11;
	setp.ne.f64 	%p123, %fd68, %fd315;
	setp.gtu.f64 	%p124, %fd69, 0d433FFFFFFFFFFFFF;
	or.pred  	%p125, %p123, %p124;
	@%p125 bra 	$L__BB0_111;

	cvt.rzi.s64.f64 	%rd12, %fd69;
	setp.gt.s64 	%p126, %rd12, 9007199254740991;
	@%p126 bra 	$L__BB0_111;

	cvt.rn.f64.s64 	%fd316, %rd12;
	setp.ne.f64 	%p127, %fd69, %fd316;
	setp.gtu.f64 	%p128, %fd70, 0d433FFFFFFFFFFFFF;
	or.pred  	%p129, %p127, %p128;
	@%p129 bra 	$L__BB0_111;

	cvt.rzi.s64.f64 	%rd31, %fd70;
	setp.lt.s64 	%p130, %rd31, 9007199254740992;
	cvt.rn.f64.s64 	%fd317, %rd31;
	setp.equ.f64 	%p131, %fd70, %fd317;
	and.pred  	%p132, %p130, %p131;
	@%p132 bra 	$L__BB0_112;

$L__BB0_111:
	mul.f64 	%fd319, %fd69, 0d3CF0000000000000;
	setp.lt.f64 	%p133, %fd68, %fd319;
	mul.f64 	%fd320, %fd70, 0d3CF0000000000000;
	setp.lt.f64 	%p134, %fd68, %fd320;
	and.pred  	%p135, %p133, %p134;
	@%p135 bra 	$L__BB0_113;

$L__BB0_112:
	add.f64 	%fd347, %fd23, %fd346;

$L__BB0_113:
	ld.param.u64 	%rd39, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_0];
	add.s64 	%rd33, %rd39, %rd24;
	st.global.f64 	[%rd33], %fd347;
	ret;

$L__BB0_5:
	mov.f64 	%fd76, 0d3FFCAC083126E979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd76;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd76;
	}
	and.b32  	%r24, %r23, 2147483647;
	setp.ne.s32 	%p6, %r24, 2146435072;
	setp.ne.s32 	%p7, %r22, 0;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_6;

$L__BB0_8:
	mov.f64 	%fd79, 0d3FE0000000000000;
	mul.rn.f64 	%fd80, %fd79, %fd76;
	cvt.rzi.f64.f64 	%fd81, %fd80;
	mov.f64 	%fd82, 0d4000000000000000;
	mul.rn.f64 	%fd83, %fd82, %fd81;
	sub.f64 	%fd84, %fd76, %fd83;
	abs.f64 	%fd6, %fd84;
	setp.eq.f64 	%p11, %fd3, 0d0000000000000000;
	@%p11 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_9;

$L__BB0_25:
	setp.eq.f64 	%p27, %fd6, 0d3FF0000000000000;
	selp.f64 	%fd329, %fd3, 0d0000000000000000, %p27;
	bra.uni 	$L__BB0_28;

$L__BB0_6:
	setp.eq.f64 	%p9, %fd3, 0dBFF0000000000000;
	@%p9 bra 	$L__BB0_28;

	setp.gt.f64 	%p10, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd329, 0d7FF0000000000000, 0d0000000000000000, %p10;
	bra.uni 	$L__BB0_28;

$L__BB0_9:
	setp.eq.f64 	%p12, %fd3, 0dFFF0000000000000;
	@%p12 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_10;

$L__BB0_23:
	setp.neu.f64 	%p26, %fd6, 0d3FF0000000000000;
	mov.f64 	%fd329, 0d7FF0000000000000;
	@%p26 bra 	$L__BB0_28;

	mov.f64 	%fd329, 0dFFF0000000000000;
	bra.uni 	$L__BB0_28;

$L__BB0_10:
	setp.geu.f64 	%p13, %fd3, 0d0000000000000000;
	@%p13 bra 	$L__BB0_12;

	mov.f64 	%fd86, 0d3FFCAC083126E979;
	cvt.rzi.f64.f64 	%fd87, %fd86;
	setp.neu.f64 	%p14, %fd87, 0d3FFCAC083126E979;
	mov.f64 	%fd329, 0dFFF8000000000000;
	@%p14 bra 	$L__BB0_28;

$L__BB0_12:
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r76}, %fd4; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r75, hi}, %fd4; 
	}
	// end inline asm
	shr.u32 	%r27, %r76, 20;
	and.b32  	%r77, %r27, 2047;
	setp.ne.s32 	%p15, %r77, 0;
	@%p15 bra 	$L__BB0_14;

	mov.f64 	%fd92, 0d4350000000000000;
	mul.rn.f64 	%fd91, %fd4, %fd92;
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r76}, %fd91; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r75, hi}, %fd91; 
	}
	// end inline asm
	shr.u32 	%r30, %r76, 20;
	and.b32  	%r31, %r30, 2047;
	add.s32 	%r77, %r31, -54;

$L__BB0_14:
	add.s32 	%r78, %r77, -1023;
	and.b32  	%r34, %r76, -2146435073;
	or.b32  	%r33, %r34, 1072693248;
	// begin inline asm
	mov.b64 	%fd326, {%r75, %r33};
	// end inline asm
	setp.lt.u32 	%p16, %r33, 1073127583;
	@%p16 bra 	$L__BB0_16;

	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r35, hi}, %fd326; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r36}, %fd326; 
	}
	// end inline asm
	add.s32 	%r38, %r36, -1048576;
	// begin inline asm
	mov.b64 	%fd326, {%r35, %r38};
	// end inline asm
	add.s32 	%r78, %r77, -1022;

$L__BB0_16:
	add.f64 	%fd181, %fd326, 0d3FF0000000000000;
	mov.f64 	%fd182, 0d3FF0000000000000;
	rcp.rn.f64 	%fd183, %fd181;
	add.f64 	%fd123, %fd326, 0dBFF0000000000000;
	mul.rn.f64 	%fd184, %fd123, %fd183;
	add.f64 	%fd171, %fd184, %fd184;
	mul.rn.f64 	%fd119, %fd171, %fd171;
	mov.f64 	%fd98, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd100, 0d3ED0F5D241AD3B5A;
	// begin inline asm
	fma.rn.f64 	%fd97, %fd98, %fd119, %fd100;
	// end inline asm
	mov.f64 	%fd104, 0d3EF3B20A75488A3F;
	// begin inline asm
	fma.rn.f64 	%fd101, %fd97, %fd119, %fd104;
	// end inline asm
	mov.f64 	%fd108, 0d3F1745CDE4FAECD5;
	// begin inline asm
	fma.rn.f64 	%fd105, %fd101, %fd119, %fd108;
	// end inline asm
	mov.f64 	%fd112, 0d3F3C71C7258A578B;
	// begin inline asm
	fma.rn.f64 	%fd109, %fd105, %fd119, %fd112;
	// end inline asm
	mov.f64 	%fd116, 0d3F6249249242B910;
	// begin inline asm
	fma.rn.f64 	%fd113, %fd109, %fd119, %fd116;
	// end inline asm
	mov.f64 	%fd120, 0d3F89999999999DFB;
	// begin inline asm
	fma.rn.f64 	%fd117, %fd113, %fd119, %fd120;
	// end inline asm
	mul.rn.f64 	%fd185, %fd117, %fd119;
	sub.f64 	%fd186, %fd123, %fd171;
	mov.f64 	%fd187, 0d4000000000000000;
	mul.rn.f64 	%fd124, %fd187, %fd186;
	neg.f64 	%fd122, %fd171;
	// begin inline asm
	fma.rn.f64 	%fd121, %fd122, %fd123, %fd124;
	// end inline asm
	mul.rn.f64 	%fd167, %fd183, %fd121;
	add.f64 	%fd188, %fd185, 0d3FB5555555555555;
	mov.f64 	%fd189, 0d3FB5555555555555;
	sub.f64 	%fd190, %fd189, %fd188;
	add.f64 	%fd191, %fd185, %fd190;
	add.f64 	%fd192, %fd191, 0d0000000000000000;
	add.f64 	%fd193, %fd192, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd134, %fd188, %fd193;
	sub.f64 	%fd194, %fd188, %fd134;
	add.f64 	%fd138, %fd193, %fd194;
	mul.rn.f64 	%fd195, %fd134, %fd171;
	neg.f64 	%fd128, %fd195;
	// begin inline asm
	fma.rn.f64 	%fd125, %fd134, %fd171, %fd128;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd129, %fd138, %fd167, %fd125;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd133, %fd134, %fd167, %fd129;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd137, %fd138, %fd171, %fd133;
	// end inline asm
	add.f64 	%fd150, %fd195, %fd137;
	sub.f64 	%fd196, %fd195, %fd150;
	add.f64 	%fd154, %fd137, %fd196;
	mul.rn.f64 	%fd197, %fd150, %fd171;
	neg.f64 	%fd144, %fd197;
	// begin inline asm
	fma.rn.f64 	%fd141, %fd150, %fd171, %fd144;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd145, %fd154, %fd167, %fd141;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd149, %fd150, %fd167, %fd145;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd153, %fd154, %fd171, %fd149;
	// end inline asm
	add.f64 	%fd166, %fd197, %fd153;
	sub.f64 	%fd198, %fd197, %fd166;
	add.f64 	%fd170, %fd153, %fd198;
	mul.rn.f64 	%fd199, %fd166, %fd171;
	neg.f64 	%fd160, %fd199;
	// begin inline asm
	fma.rn.f64 	%fd157, %fd166, %fd171, %fd160;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd161, %fd170, %fd167, %fd157;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd165, %fd166, %fd167, %fd161;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd169, %fd170, %fd171, %fd165;
	// end inline asm
	add.f64 	%fd200, %fd199, %fd169;
	sub.f64 	%fd201, %fd199, %fd200;
	add.f64 	%fd202, %fd169, %fd201;
	add.f64 	%fd203, %fd171, %fd200;
	sub.f64 	%fd204, %fd171, %fd203;
	add.f64 	%fd205, %fd200, %fd204;
	add.f64 	%fd206, %fd202, %fd205;
	add.f64 	%fd207, %fd167, %fd206;
	add.f64 	%fd208, %fd203, %fd207;
	sub.f64 	%fd209, %fd203, %fd208;
	add.f64 	%fd210, %fd207, %fd209;
	cvt.rn.f64.s32 	%fd211, %r78;
	mov.f64 	%fd212, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd213, %fd211, %fd212;
	mov.f64 	%fd214, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd215, %fd211, %fd214;
	add.f64 	%fd216, %fd213, %fd208;
	sub.f64 	%fd217, %fd213, %fd216;
	add.f64 	%fd218, %fd208, %fd217;
	add.f64 	%fd219, %fd210, %fd218;
	add.f64 	%fd220, %fd215, %fd219;
	add.f64 	%fd174, %fd216, %fd220;
	sub.f64 	%fd221, %fd216, %fd174;
	add.f64 	%fd178, %fd220, %fd221;
	mov.f64 	%fd179, 0d3FFCAC083126E979;
	mul.rn.f64 	%fd222, %fd174, %fd179;
	neg.f64 	%fd176, %fd222;
	// begin inline asm
	fma.rn.f64 	%fd173, %fd174, %fd179, %fd176;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd177, %fd178, %fd179, %fd173;
	// end inline asm
	add.f64 	%fd10, %fd222, %fd177;
	sub.f64 	%fd223, %fd222, %fd10;
	add.f64 	%fd11, %fd177, %fd223;
	mov.f64 	%fd224, 0d4338000000000000;
	mov.f64 	%fd225, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd226, %fd10, %fd225, %fd224;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd226;
	}
	mov.f64 	%fd227, 0dC338000000000000;
	add.rn.f64 	%fd228, %fd226, %fd227;
	mov.f64 	%fd229, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd230, %fd228, %fd229, %fd10;
	mov.f64 	%fd231, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd232, %fd228, %fd231, %fd230;
	mov.f64 	%fd233, 0d3E928AF3FCA213EA;
	mov.f64 	%fd234, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd235, %fd234, %fd232, %fd233;
	mov.f64 	%fd236, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd237, %fd235, %fd232, %fd236;
	mov.f64 	%fd238, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd239, %fd237, %fd232, %fd238;
	mov.f64 	%fd240, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd241, %fd239, %fd232, %fd240;
	mov.f64 	%fd242, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd243, %fd241, %fd232, %fd242;
	mov.f64 	%fd244, 0d3F81111111122322;
	fma.rn.f64 	%fd245, %fd243, %fd232, %fd244;
	mov.f64 	%fd246, 0d3FA55555555502A1;
	fma.rn.f64 	%fd247, %fd245, %fd232, %fd246;
	mov.f64 	%fd248, 0d3FC5555555555511;
	fma.rn.f64 	%fd249, %fd247, %fd232, %fd248;
	mov.f64 	%fd250, 0d3FE000000000000B;
	fma.rn.f64 	%fd251, %fd249, %fd232, %fd250;
	fma.rn.f64 	%fd252, %fd251, %fd232, %fd182;
	fma.rn.f64 	%fd253, %fd252, %fd232, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd253;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd253;
	}
	shl.b32 	%r39, %r13, 20;
	add.s32 	%r40, %r15, %r39;
	mov.b64 	%fd329, {%r14, %r40};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd10;
	}
	mov.b32 	%f2, %r41;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p17, %f1, 0f4086232B;
	@%p17 bra 	$L__BB0_19;

	setp.lt.f64 	%p18, %fd10, 0d0000000000000000;
	add.f64 	%fd254, %fd10, 0d7FF0000000000000;
	selp.f64 	%fd329, 0d0000000000000000, %fd254, %p18;
	setp.geu.f32 	%p19, %f1, 0f40874800;
	@%p19 bra 	$L__BB0_19;

	mov.f64 	%fd324, 0d4338000000000000;
	mov.f64 	%fd323, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd322, %fd10, %fd323, %fd324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd322;
	}
	shr.u32 	%r42, %r74, 31;
	add.s32 	%r43, %r74, %r42;
	shr.s32 	%r44, %r43, 1;
	shl.b32 	%r45, %r44, 20;
	add.s32 	%r46, %r15, %r45;
	mov.b64 	%fd255, {%r14, %r46};
	sub.s32 	%r47, %r74, %r44;
	shl.b32 	%r48, %r47, 20;
	add.s32 	%r49, %r48, 1072693248;
	mov.u32 	%r50, 0;
	mov.b64 	%fd256, {%r50, %r49};
	mul.f64 	%fd329, %fd255, %fd256;

$L__BB0_19:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd329;
	}
	and.b32  	%r52, %r51, 2147483647;
	setp.eq.s32 	%p20, %r52, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd329;
	}
	setp.eq.s32 	%p21, %r53, 0;
	and.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB0_21;

	// begin inline asm
	fma.rn.f64 	%fd329, %fd329, %fd11, %fd329;
	// end inline asm

$L__BB0_21:
	setp.neu.f64 	%p23, %fd6, 0d3FF0000000000000;
	or.pred  	%p25, %p13, %p23;
	@%p25 bra 	$L__BB0_28;

	mov.b64 	%rd22, %fd329;
	xor.b64  	%rd23, %rd22, -9223372036854775808;
	mov.b64 	%fd329, %rd23;
	bra.uni 	$L__BB0_28;

}

  